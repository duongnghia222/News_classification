{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ca897cb5bc5c48a5b07aef004b48e6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6f2aa1bb3e5475788d4beacb53a84c2",
              "IPY_MODEL_1ce085b4f6824c7e9545b2149c55881e",
              "IPY_MODEL_3cda02b123824f2b96410a4ddf4383c4"
            ],
            "layout": "IPY_MODEL_e4c6430487224597b1d8691d425058e2"
          }
        },
        "b6f2aa1bb3e5475788d4beacb53a84c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b6a72d7d834285943a0f7d44e7edf5",
            "placeholder": "​",
            "style": "IPY_MODEL_7f35cd7eefb945868c066cc78dfdf570",
            "value": "Sanity Checking DataLoader 0:   0%"
          }
        },
        "1ce085b4f6824c7e9545b2149c55881e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27a2d4ecc75c42ada6b24a11d8f6eb5d",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_562a5eddbc904ebbaeaf1081a0cdc38a",
            "value": 0
          }
        },
        "3cda02b123824f2b96410a4ddf4383c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f19edfe0084276b1cfc519a1f55e14",
            "placeholder": "​",
            "style": "IPY_MODEL_7780d5ed290e45d19d783cc392cd6b79",
            "value": " 0/50 [00:00&lt;?, ?it/s]"
          }
        },
        "e4c6430487224597b1d8691d425058e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "f3b6a72d7d834285943a0f7d44e7edf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f35cd7eefb945868c066cc78dfdf570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27a2d4ecc75c42ada6b24a11d8f6eb5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562a5eddbc904ebbaeaf1081a0cdc38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6f19edfe0084276b1cfc519a1f55e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7780d5ed290e45d19d783cc392cd6b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "RcpyAVGwavy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import lib"
      ],
      "metadata": {
        "id": "WOoawOFSYKbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import LayerNorm\n",
        "from torch.nn import functional as F\n",
        "from transformers import AutoModel, AutoTokenizer, AdamW, get_cosine_schedule_with_warmup\n",
        "import json\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pytorch_lightning as pl\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import math\n",
        "from google.colab import drive\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "03PaRuIGYETu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ad424f-e10c-4332-c83d-213d668991ad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dataset"
      ],
      "metadata": {
        "id": "t09nEVgzGNkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "y52sgdpZb-Dp",
        "outputId": "02253005-e13d-4d46-f8e9-adb05c864f63"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-65b5696c-e83c-4237-a57b-1254797cb938\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-65b5696c-e83c-4237-a57b-1254797cb938\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving vietnamese-stopwords.txt to vietnamese-stopwords.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqb9RhkQGo5a",
        "outputId": "504972a4-5ba8-43d8-8cbb-7f22d7a4894d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/raw_data.csv', encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "Bnge752SB8Ez"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Data"
      ],
      "metadata": {
        "id": "aqu8-QjYBzWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "k7U3B_R3CflP",
        "outputId": "540e0e63-277b-4a0e-8962-3395e061895d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Content Label\n",
              "0  Vingroup báo lãi hơn 3.600 tỷ đồng, doanh thu ...   VIC\n",
              "1  HAGL Agrico (HNG) lỗ quý thứ 5 liên tiếp. Giá ...   HNG\n",
              "2  Vingroup lãi ròng 1.028 tỷ đồng nửa đầu năm, t...   VIC\n",
              "3  Một doanh nghiệp khoáng sản đã vượt 153% mục t...   KSV\n",
              "4  Doanh nghiệp thép từ lớn đến nhỏ đều báo lỗ qu...   HPG"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca6b39fd-e41c-4726-bbf9-9d88562a8e4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vingroup báo lãi hơn 3.600 tỷ đồng, doanh thu ...</td>\n",
              "      <td>VIC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAGL Agrico (HNG) lỗ quý thứ 5 liên tiếp. Giá ...</td>\n",
              "      <td>HNG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vingroup lãi ròng 1.028 tỷ đồng nửa đầu năm, t...</td>\n",
              "      <td>VIC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Một doanh nghiệp khoáng sản đã vượt 153% mục t...</td>\n",
              "      <td>KSV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Doanh nghiệp thép từ lớn đến nhỏ đều báo lỗ qu...</td>\n",
              "      <td>HPG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca6b39fd-e41c-4726-bbf9-9d88562a8e4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca6b39fd-e41c-4726-bbf9-9d88562a8e4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca6b39fd-e41c-4726-bbf9-9d88562a8e4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of words in each article's content and number of times a class appear\n",
        "df['Word Count'] = df['Content'].apply(lambda x: len(str(x).split()))\n",
        "df['Class Count'] = df.groupby('Label')['Label'].transform('count')\n",
        "\n",
        "# Calculate statistics for word count\n",
        "df['Word Count'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-evHq83aB4CI",
        "outputId": "b98df249-6082-4f0b-ce76-ab856672d536"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    10396.000000\n",
              "mean       607.325414\n",
              "std        352.123889\n",
              "min         46.000000\n",
              "25%        381.000000\n",
              "50%        514.000000\n",
              "75%        725.250000\n",
              "max       4235.000000\n",
              "Name: Word Count, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9RvaCV55DsfU",
        "outputId": "5ff8e546-081b-4ede-b11b-bd03840be40c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Content Label  Word Count  \\\n",
              "0  Vingroup báo lãi hơn 3.600 tỷ đồng, doanh thu ...   VIC         599   \n",
              "1  HAGL Agrico (HNG) lỗ quý thứ 5 liên tiếp. Giá ...   HNG         642   \n",
              "2  Vingroup lãi ròng 1.028 tỷ đồng nửa đầu năm, t...   VIC         577   \n",
              "3  Một doanh nghiệp khoáng sản đã vượt 153% mục t...   KSV         430   \n",
              "4  Doanh nghiệp thép từ lớn đến nhỏ đều báo lỗ qu...   HPG        1247   \n",
              "\n",
              "   Class Count  \n",
              "0          108  \n",
              "1           65  \n",
              "2          108  \n",
              "3            3  \n",
              "4          197  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d23160b6-3f69-40d6-a3b3-73717accc193\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>Label</th>\n",
              "      <th>Word Count</th>\n",
              "      <th>Class Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vingroup báo lãi hơn 3.600 tỷ đồng, doanh thu ...</td>\n",
              "      <td>VIC</td>\n",
              "      <td>599</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAGL Agrico (HNG) lỗ quý thứ 5 liên tiếp. Giá ...</td>\n",
              "      <td>HNG</td>\n",
              "      <td>642</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vingroup lãi ròng 1.028 tỷ đồng nửa đầu năm, t...</td>\n",
              "      <td>VIC</td>\n",
              "      <td>577</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Một doanh nghiệp khoáng sản đã vượt 153% mục t...</td>\n",
              "      <td>KSV</td>\n",
              "      <td>430</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Doanh nghiệp thép từ lớn đến nhỏ đều báo lỗ qu...</td>\n",
              "      <td>HPG</td>\n",
              "      <td>1247</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d23160b6-3f69-40d6-a3b3-73717accc193')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d23160b6-3f69-40d6-a3b3-73717accc193 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d23160b6-3f69-40d6-a3b3-73717accc193');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histogram for word count\n",
        "plt.hist(df['Word Count'], bins=20, color='skyblue', edgecolor='black')\n",
        "plt.title('Histogram of Word Count')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "8Y7NA9bxCK40",
        "outputId": "2b4d7b68-2084-47f1-b863-110a022cbe4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrence of each unique label\n",
        "label_counts = df['Label'].value_counts()\n",
        "print(label_counts.describe())\n",
        "\n",
        "# Loop over each unique label and print its count\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"Label: {label}, Count: {count}\")"
      ],
      "metadata": {
        "id": "wGjBHZ7TB8Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracted_df\n",
        "e_df = df.loc[df['Class Count'] > 5].sort_values(by=\"Class Count\", ascending=False)\n",
        "e_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OZpZDJiB8Sx",
        "outputId": "97ff1b3b-a251-40d1-959d-c429fa01e9b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Content        9222\n",
              "Label          9222\n",
              "Word Count     9222\n",
              "Class Count    9222\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_classes = e_df['Label'].nunique()\n",
        "number_of_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5IyPXDJEwmh",
        "outputId": "05391673-39c9-49f4-c7c9-d707583b497b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "350"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing Dataset"
      ],
      "metadata": {
        "id": "6NLAa4szYUhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean text"
      ],
      "metadata": {
        "id": "oAAmnOmSXj5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as f:\n",
        "    vietnamese_stopwords = f.read().splitlines()\n",
        "\n",
        "vietnamese_stopwords[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnWMnVIDXpl1",
        "outputId": "6d5bf7af-e85e-41f2-a8f2-8dfd87a41792"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a lô',\n",
              " 'a ha',\n",
              " 'ai',\n",
              " 'ai ai',\n",
              " 'ai nấy',\n",
              " 'ai đó',\n",
              " 'alô',\n",
              " 'amen',\n",
              " 'anh',\n",
              " 'anh ấy']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(txt):\n",
        "    txt = re.sub('\\s+', ' ', txt)\n",
        "    txt = txt.replace('.','')\n",
        "    txt = re.sub('\\n', ' ', txt)\n",
        "    txt = [word_tokenize(wrd) for wrd in txt.split() if wrd not in vietnamese_stopwords]\n",
        "    txt = [item[0] for item in txt]\n",
        "    txt = ' '.join(txt)\n",
        "    return txt\n",
        "\n",
        "clean_text(\" VinFast chính thức vận hành 35 showroom xe máy điện kết hợp trung tâm trải nghiệm Vin3S tại 24 tỉnh, thành phố trên cả nước\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ckULHpAOYP9z",
        "outputId": "41d48367-8076-47ef-d514-5af18c2adcbe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'VinFast thức vận hành 35 showroom xe máy điện kết hợp trung tâm trải nghiệm Vin3S 24 tỉnh thành phố'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split trainset valset"
      ],
      "metadata": {
        "id": "pfz_FReFILAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, valset = train_test_split(e_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Z8LKnxN4IOJJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ArticleDataset Class"
      ],
      "metadata": {
        "id": "gymaeNCFqaPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ArticleDataset(Dataset):\n",
        "    def __init__(self, data, labels, tokenizer, max_length=512):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text=item.Content,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "_zn9GjIyYYX7"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform labels"
      ],
      "metadata": {
        "id": "d4CCJN2WY4iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJJBTXFEbwls",
        "outputId": "2f5a7202-cc59-4ae8-9e57-8426eabce513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_list = e_df['Label'].tolist()\n",
        "print(labels_list[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n0XXsj4tSQG",
        "outputId": "1d7d244b-2e31-450b-a7dc-adf1a52d962c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HPG', 'HPG', 'HPG', 'HPG', 'HPG', 'HPG', 'HPG', 'HPG', 'HPG', 'HPG']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels_list).tolist()\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "rqVhpg4LdRgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2a9005-b89b-4376-a70e-991891420514"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 331, 125, 125, 125, 173, 173, 173, 173, 125, 173, 125, 173, 125, 173, 125, 125, 125, 125, 173, 173, 125, 173, 173, 173, 173, 125, 173, 125, 173, 125, 125, 173, 173, 173, 173, 173, 125, 173, 173, 173, 173, 125, 173, 125, 173, 125, 125, 125, 173, 125, 125, 125, 125, 173, 173, 125, 125, 173, 125, 125, 125, 125, 125, 173, 125, 125, 173, 125, 173, 125, 125, 173, 173, 173, 125, 125, 173, 125, 173, 125, 125, 173, 173, 173, 173, 125, 173, 125, 125, 173, 173, 125, 173, 125, 125, 173, 173, 125, 125, 173, 125, 173, 173, 173, 173, 125, 173, 125, 173, 125, 125, 125, 173, 173, 173, 173, 173, 125, 173, 125, 125, 173, 173, 173, 125, 125, 125, 125, 125, 173, 173, 173, 125, 173, 173, 173, 173, 173, 173, 173, 173, 173, 125, 125, 125, 125, 125, 125, 125, 125, 173, 125, 125, 173, 125, 125, 173, 173, 125, 173, 125, 125, 125, 173, 125, 125, 125, 125, 173, 173, 173, 125, 173, 173, 173, 125, 125, 173, 173, 173, 173, 125, 173, 173, 173, 173, 173, 173, 173, 125, 125, 125, 125, 125, 173, 125, 125, 173, 173, 125, 125, 173, 173, 125, 173, 125, 173, 125, 125, 173, 173, 125, 173, 125, 173, 173, 125, 125, 125, 125, 125, 125, 125, 173, 173, 125, 125, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 322, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 22, 319, 22, 319, 319, 22, 319, 22, 22, 22, 319, 22, 22, 319, 319, 319, 22, 22, 22, 319, 319, 319, 22, 22, 319, 22, 319, 22, 22, 22, 22, 22, 22, 22, 22, 319, 22, 319, 22, 22, 319, 22, 319, 22, 22, 319, 22, 22, 319, 319, 319, 22, 319, 319, 22, 319, 22, 22, 319, 22, 22, 22, 22, 22, 319, 22, 319, 22, 319, 319, 319, 22, 319, 22, 22, 319, 22, 22, 319, 319, 22, 319, 22, 319, 22, 22, 319, 22, 22, 22, 319, 319, 319, 22, 319, 22, 22, 319, 22, 319, 319, 22, 22, 319, 319, 319, 22, 319, 22, 22, 319, 22, 319, 319, 319, 22, 319, 22, 22, 319, 22, 22, 319, 319, 319, 319, 319, 22, 319, 22, 22, 22, 319, 319, 319, 319, 319, 319, 319, 319, 22, 319, 319, 319, 319, 319, 319, 22, 319, 319, 22, 319, 22, 22, 22, 22, 319, 22, 22, 319, 319, 319, 319, 319, 319, 22, 319, 22, 319, 319, 22, 319, 22, 319, 22, 319, 22, 22, 22, 22, 22, 319, 319, 22, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 94, 325, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 325, 325, 94, 325, 325, 325, 325, 325, 94, 94, 94, 325, 325, 94, 325, 94, 325, 325, 325, 325, 94, 325, 94, 94, 325, 94, 325, 94, 325, 325, 325, 325, 94, 94, 325, 325, 325, 325, 325, 94, 325, 325, 94, 94, 94, 94, 325, 94, 94, 94, 325, 325, 94, 94, 325, 94, 325, 94, 94, 325, 325, 325, 94, 325, 325, 325, 325, 325, 325, 94, 325, 94, 325, 94, 94, 325, 94, 94, 94, 325, 94, 94, 325, 325, 94, 94, 325, 325, 94, 325, 94, 94, 94, 325, 325, 325, 325, 325, 325, 94, 94, 325, 325, 94, 325, 325, 325, 94, 94, 325, 94, 94, 325, 94, 94, 94, 325, 94, 94, 325, 94, 94, 325, 325, 94, 94, 325, 325, 94, 94, 94, 94, 325, 325, 94, 94, 325, 94, 94, 325, 94, 325, 325, 325, 94, 325, 325, 325, 94, 94, 325, 94, 198, 84, 84, 198, 84, 84, 198, 84, 198, 84, 198, 198, 198, 84, 84, 198, 84, 198, 84, 198, 84, 198, 198, 84, 84, 84, 84, 198, 198, 198, 198, 198, 84, 198, 198, 84, 84, 84, 198, 198, 84, 198, 198, 198, 84, 84, 84, 198, 198, 198, 84, 84, 84, 198, 198, 198, 198, 84, 84, 198, 84, 84, 198, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 198, 84, 84, 198, 84, 198, 198, 198, 198, 84, 84, 198, 198, 84, 84, 84, 198, 84, 198, 84, 198, 198, 198, 198, 198, 198, 84, 198, 84, 198, 198, 84, 84, 198, 84, 198, 84, 198, 84, 84, 198, 198, 198, 198, 198, 198, 84, 198, 198, 198, 84, 198, 84, 198, 84, 198, 84, 84, 198, 198, 84, 84, 198, 198, 84, 84, 84, 84, 198, 84, 198, 84, 84, 84, 198, 84, 198, 84, 198, 198, 198, 198, 84, 84, 84, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 206, 120, 206, 206, 120, 206, 120, 120, 206, 120, 120, 206, 206, 206, 120, 206, 120, 206, 206, 206, 120, 120, 206, 206, 206, 120, 120, 206, 206, 120, 120, 206, 120, 206, 206, 120, 120, 120, 120, 120, 206, 120, 120, 120, 206, 206, 120, 120, 120, 120, 120, 120, 206, 206, 120, 206, 120, 206, 206, 206, 206, 120, 120, 206, 206, 206, 120, 120, 120, 120, 120, 206, 120, 120, 206, 120, 120, 120, 120, 206, 120, 120, 120, 206, 206, 120, 120, 120, 206, 206, 120, 120, 206, 206, 206, 206, 120, 206, 120, 206, 120, 206, 120, 120, 120, 206, 120, 206, 206, 206, 120, 120, 206, 206, 206, 120, 206, 206, 206, 206, 206, 206, 206, 120, 120, 206, 206, 206, 120, 206, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 231, 232, 140, 232, 140, 232, 140, 140, 140, 140, 232, 140, 232, 140, 140, 140, 232, 232, 232, 140, 232, 140, 140, 232, 232, 232, 140, 232, 140, 140, 232, 140, 232, 140, 232, 232, 140, 232, 140, 232, 140, 232, 232, 140, 140, 140, 232, 140, 140, 232, 140, 140, 232, 232, 140, 232, 140, 140, 232, 140, 232, 232, 140, 140, 232, 232, 140, 140, 232, 232, 232, 232, 140, 232, 232, 232, 140, 232, 232, 232, 232, 232, 140, 140, 232, 140, 232, 232, 232, 140, 140, 232, 140, 140, 140, 232, 140, 232, 140, 140, 232, 232, 140, 140, 140, 232, 140, 232, 232, 232, 140, 140, 140, 232, 232, 232, 232, 140, 140, 140, 140, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 316, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 347, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 182, 154, 154, 154, 182, 182, 154, 182, 154, 154, 154, 154, 182, 182, 182, 154, 154, 154, 154, 154, 154, 182, 154, 154, 154, 182, 154, 182, 154, 182, 154, 182, 154, 154, 182, 182, 154, 182, 182, 154, 154, 182, 154, 182, 182, 154, 182, 182, 182, 182, 154, 182, 182, 154, 154, 182, 182, 154, 182, 182, 154, 182, 182, 182, 182, 154, 182, 182, 154, 182, 154, 154, 154, 154, 154, 154, 154, 182, 182, 182, 182, 182, 182, 154, 154, 182, 182, 182, 182, 154, 154, 182, 154, 154, 154, 154, 182, 154, 154, 182, 154, 182, 182, 182, 154, 182, 300, 229, 300, 229, 300, 229, 300, 300, 300, 229, 300, 300, 300, 229, 229, 300, 229, 229, 300, 229, 229, 229, 300, 229, 229, 229, 229, 300, 229, 229, 300, 300, 300, 229, 229, 300, 300, 300, 300, 300, 300, 229, 229, 229, 229, 229, 229, 229, 229, 229, 300, 300, 300, 229, 300, 229, 300, 229, 300, 300, 300, 229, 300, 300, 229, 300, 300, 229, 300, 229, 229, 229, 229, 229, 300, 229, 229, 300, 300, 229, 229, 229, 229, 229, 300, 229, 300, 300, 229, 300, 300, 300, 300, 229, 300, 229, 229, 300, 300, 229, 300, 300, 300, 300, 76, 237, 76, 76, 237, 178, 178, 237, 237, 237, 178, 237, 237, 237, 178, 178, 76, 237, 178, 178, 178, 237, 76, 237, 76, 237, 76, 178, 237, 178, 237, 178, 178, 76, 237, 76, 76, 76, 178, 178, 237, 237, 76, 237, 178, 76, 237, 76, 237, 178, 237, 76, 178, 76, 237, 76, 76, 178, 178, 178, 178, 76, 178, 76, 237, 178, 178, 178, 76, 237, 76, 237, 76, 76, 237, 237, 178, 237, 76, 178, 178, 237, 237, 237, 76, 178, 237, 237, 237, 237, 237, 178, 237, 178, 76, 76, 237, 76, 237, 178, 237, 76, 76, 76, 76, 178, 76, 76, 76, 237, 178, 178, 76, 237, 76, 76, 76, 237, 178, 178, 76, 76, 76, 178, 237, 237, 178, 178, 76, 178, 178, 178, 178, 237, 76, 237, 237, 178, 178, 237, 178, 76, 178, 76, 76, 178, 76, 237, 76, 178, 178, 76, 237, 104, 63, 104, 104, 104, 63, 104, 63, 63, 104, 104, 104, 104, 23, 104, 63, 63, 104, 23, 63, 63, 23, 63, 23, 23, 23, 63, 63, 63, 104, 23, 63, 23, 23, 23, 104, 23, 104, 23, 23, 104, 63, 63, 23, 63, 63, 63, 104, 104, 23, 63, 104, 63, 104, 23, 104, 63, 104, 104, 104, 23, 23, 104, 104, 104, 23, 23, 63, 63, 63, 63, 63, 63, 63, 104, 104, 104, 104, 63, 104, 23, 63, 23, 104, 23, 63, 63, 63, 63, 104, 23, 23, 23, 23, 63, 104, 23, 23, 23, 23, 23, 104, 104, 63, 23, 23, 23, 23, 104, 104, 104, 104, 104, 63, 23, 104, 104, 63, 23, 63, 104, 23, 104, 23, 104, 23, 63, 104, 104, 63, 23, 63, 63, 23, 63, 63, 23, 63, 63, 63, 23, 23, 63, 23, 23, 104, 23, 95, 95, 144, 144, 144, 144, 95, 95, 144, 144, 144, 144, 144, 95, 95, 144, 95, 144, 144, 95, 144, 95, 144, 95, 95, 144, 95, 144, 95, 144, 144, 95, 95, 95, 144, 95, 95, 95, 95, 144, 144, 144, 144, 95, 144, 144, 144, 95, 144, 144, 144, 95, 144, 95, 95, 144, 95, 95, 95, 95, 95, 144, 95, 144, 95, 144, 144, 95, 95, 144, 144, 95, 95, 144, 144, 144, 144, 144, 95, 144, 144, 95, 95, 95, 144, 95, 144, 95, 95, 95, 95, 95, 95, 144, 95, 144, 170, 5, 18, 18, 18, 170, 5, 170, 18, 170, 5, 18, 5, 170, 170, 5, 170, 18, 5, 18, 170, 170, 18, 170, 18, 18, 18, 5, 170, 170, 5, 18, 5, 18, 18, 5, 18, 18, 5, 170, 5, 170, 170, 170, 170, 5, 18, 18, 170, 170, 5, 5, 18, 170, 5, 170, 5, 170, 5, 170, 5, 18, 170, 18, 5, 5, 5, 170, 18, 170, 170, 170, 170, 5, 18, 18, 170, 18, 5, 18, 5, 170, 18, 18, 170, 170, 5, 5, 18, 5, 5, 170, 5, 18, 18, 18, 170, 18, 5, 18, 5, 18, 5, 18, 170, 18, 5, 170, 170, 170, 18, 5, 5, 170, 170, 5, 18, 18, 5, 5, 170, 170, 18, 5, 18, 5, 170, 5, 5, 18, 18, 18, 5, 170, 18, 170, 5, 5, 170, 18, 5, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 199, 133, 199, 133, 199, 199, 133, 133, 199, 133, 199, 199, 199, 199, 199, 133, 133, 199, 133, 133, 199, 133, 133, 199, 133, 199, 133, 199, 199, 133, 133, 199, 133, 133, 199, 199, 133, 199, 133, 199, 199, 133, 199, 133, 133, 133, 133, 199, 199, 199, 199, 133, 199, 133, 133, 199, 199, 133, 199, 133, 133, 199, 133, 133, 133, 133, 133, 199, 199, 133, 199, 133, 199, 133, 199, 199, 199, 133, 133, 133, 199, 133, 199, 133, 199, 199, 133, 199, 133, 199, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 223, 223, 293, 293, 293, 293, 223, 293, 293, 293, 293, 223, 223, 223, 223, 293, 293, 293, 223, 223, 293, 223, 223, 223, 293, 293, 293, 223, 293, 293, 293, 223, 293, 293, 293, 223, 223, 223, 293, 293, 293, 293, 223, 223, 293, 223, 293, 293, 293, 223, 293, 293, 223, 223, 223, 223, 223, 223, 293, 293, 223, 293, 223, 293, 223, 223, 293, 223, 293, 293, 223, 223, 223, 223, 293, 223, 223, 223, 223, 293, 223, 293, 293, 223, 105, 105, 105, 105, 105, 105, 105, 203, 203, 105, 203, 203, 203, 105, 105, 203, 203, 203, 203, 105, 105, 105, 203, 105, 203, 105, 105, 105, 105, 203, 105, 105, 203, 105, 203, 203, 203, 105, 203, 105, 105, 203, 105, 203, 203, 105, 203, 203, 203, 105, 105, 203, 105, 203, 105, 105, 203, 105, 203, 203, 203, 203, 203, 203, 105, 203, 203, 203, 105, 203, 203, 203, 105, 203, 105, 105, 105, 105, 203, 105, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 204, 204, 66, 204, 66, 204, 66, 204, 66, 204, 204, 204, 66, 66, 66, 204, 204, 66, 66, 66, 66, 204, 204, 204, 66, 204, 204, 204, 66, 66, 204, 66, 66, 204, 204, 204, 66, 204, 66, 204, 204, 204, 204, 66, 66, 204, 66, 66, 204, 66, 66, 66, 204, 66, 66, 66, 66, 66, 66, 204, 204, 204, 204, 66, 204, 66, 66, 204, 204, 204, 66, 66, 66, 204, 103, 103, 289, 289, 289, 329, 103, 329, 103, 289, 103, 289, 329, 103, 103, 289, 329, 289, 329, 329, 289, 289, 103, 103, 289, 289, 103, 103, 103, 289, 329, 329, 289, 329, 329, 289, 289, 103, 103, 289, 289, 289, 103, 289, 329, 329, 289, 289, 103, 103, 289, 103, 289, 329, 329, 289, 329, 103, 289, 103, 103, 103, 103, 289, 289, 329, 329, 329, 289, 289, 329, 103, 289, 329, 103, 329, 289, 103, 329, 103, 103, 329, 103, 329, 329, 329, 329, 329, 329, 103, 289, 329, 103, 329, 289, 289, 103, 289, 329, 329, 329, 103, 329, 329, 103, 103, 289, 103, 181, 8, 10, 8, 10, 8, 8, 8, 10, 8, 181, 8, 181, 10, 10, 181, 10, 10, 181, 181, 181, 10, 10, 10, 10, 181, 10, 181, 8, 8, 8, 181, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 10, 10, 181, 10, 8, 181, 10, 10, 8, 8, 8, 8, 8, 8, 181, 181, 10, 181, 10, 8, 10, 8, 8, 181, 10, 10, 10, 181, 181, 8, 181, 10, 10, 181, 10, 181, 10, 181, 181, 10, 181, 10, 8, 181, 10, 181, 181, 8, 10, 181, 181, 181, 8, 181, 181, 181, 181, 181, 10, 10, 110, 86, 101, 233, 101, 239, 86, 86, 279, 233, 101, 101, 101, 101, 86, 279, 239, 239, 101, 233, 107, 107, 239, 239, 233, 239, 233, 101, 110, 239, 110, 279, 239, 107, 110, 279, 233, 239, 279, 233, 110, 239, 86, 101, 110, 101, 110, 239, 101, 110, 279, 279, 107, 107, 101, 86, 101, 107, 239, 239, 86, 239, 101, 101, 110, 239, 86, 107, 233, 101, 110, 86, 110, 107, 86, 86, 279, 279, 86, 110, 86, 233, 107, 110, 233, 86, 107, 107, 86, 279, 110, 279, 86, 110, 233, 239, 86, 86, 107, 101, 101, 86, 239, 279, 101, 233, 110, 110, 107, 86, 110, 107, 107, 279, 107, 239, 239, 233, 279, 279, 233, 233, 107, 110, 110, 279, 107, 233, 110, 279, 107, 239, 110, 101, 279, 107, 239, 279, 107, 107, 86, 279, 279, 107, 107, 101, 107, 233, 233, 110, 110, 110, 101, 279, 101, 239, 279, 279, 239, 86, 86, 279, 233, 233, 279, 233, 239, 239, 110, 279, 107, 233, 86, 107, 233, 110, 233, 101, 233, 86, 107, 101, 279, 233, 279, 101, 86, 233, 239, 107, 101, 101, 239, 233, 110, 239, 86, 279, 110, 239, 279, 107, 279, 233, 233, 110, 101, 101, 233, 239, 86, 107, 86, 279, 86, 107, 239, 110, 110, 101, 107, 233, 86, 101, 101, 110, 239, 279, 233, 86, 86, 233, 239, 101, 86, 107, 239, 110, 280, 30, 275, 280, 317, 317, 275, 30, 129, 129, 275, 280, 280, 317, 129, 280, 30, 30, 317, 275, 275, 280, 317, 275, 129, 30, 129, 317, 129, 317, 275, 30, 275, 280, 129, 317, 280, 317, 275, 280, 317, 280, 30, 129, 275, 129, 280, 129, 129, 275, 30, 129, 317, 30, 280, 317, 275, 275, 275, 317, 275, 275, 275, 129, 30, 30, 275, 280, 275, 280, 280, 280, 317, 129, 280, 317, 30, 30, 275, 280, 280, 275, 280, 30, 129, 280, 129, 317, 275, 275, 280, 129, 129, 129, 129, 129, 30, 30, 280, 280, 275, 129, 275, 30, 317, 275, 317, 30, 30, 275, 30, 129, 275, 129, 317, 317, 317, 275, 30, 317, 129, 30, 129, 275, 30, 317, 317, 280, 30, 30, 30, 275, 129, 129, 317, 317, 129, 129, 317, 30, 280, 280, 317, 30, 30, 317, 317, 280, 280, 129, 317, 280, 280, 317, 317, 129, 129, 275, 275, 30, 30, 280, 30, 280, 30, 44, 44, 70, 70, 44, 70, 44, 44, 70, 44, 70, 44, 70, 44, 70, 44, 44, 70, 44, 70, 70, 44, 70, 70, 70, 44, 70, 44, 44, 70, 70, 44, 44, 44, 70, 70, 70, 70, 70, 70, 70, 44, 70, 44, 44, 44, 70, 44, 44, 44, 70, 44, 70, 70, 70, 44, 70, 70, 44, 70, 44, 44, 44, 44, 271, 271, 192, 271, 192, 272, 192, 28, 115, 272, 271, 115, 28, 28, 272, 115, 192, 115, 192, 272, 271, 115, 115, 192, 192, 115, 115, 271, 271, 192, 272, 28, 272, 28, 272, 192, 272, 271, 271, 115, 115, 272, 192, 192, 272, 192, 271, 192, 271, 271, 271, 192, 272, 271, 28, 115, 115, 28, 271, 271, 271, 115, 271, 28, 28, 115, 28, 28, 28, 115, 192, 28, 272, 271, 28, 192, 115, 192, 272, 272, 28, 28, 272, 115, 272, 192, 115, 115, 28, 192, 28, 272, 115, 115, 115, 271, 272, 28, 28, 271, 28, 272, 115, 115, 28, 272, 272, 192, 115, 272, 115, 271, 272, 271, 271, 28, 28, 115, 271, 272, 271, 272, 28, 28, 271, 192, 271, 271, 115, 115, 192, 272, 192, 28, 28, 192, 192, 192, 192, 192, 272, 192, 28, 192, 272, 115, 272, 271, 272, 28, 161, 340, 340, 226, 226, 161, 161, 161, 222, 226, 79, 340, 312, 312, 340, 226, 312, 161, 222, 222, 161, 340, 340, 161, 161, 340, 161, 340, 161, 312, 340, 79, 340, 340, 79, 222, 79, 340, 161, 161, 222, 79, 222, 222, 340, 79, 79, 226, 340, 340, 222, 340, 340, 340, 226, 312, 340, 222, 161, 340, 161, 226, 222, 226, 312, 340, 161, 79, 226, 312, 79, 226, 226, 161, 226, 312, 312, 79, 226, 312, 161, 222, 226, 312, 222, 312, 79, 79, 312, 161, 222, 79, 226, 312, 340, 226, 161, 226, 340, 79, 161, 312, 222, 312, 79, 340, 222, 312, 312, 222, 226, 79, 340, 222, 226, 79, 222, 222, 161, 222, 222, 340, 226, 312, 222, 79, 79, 222, 340, 222, 226, 79, 79, 312, 226, 79, 226, 79, 312, 312, 226, 312, 161, 161, 340, 312, 161, 161, 340, 161, 222, 312, 312, 79, 222, 226, 79, 222, 226, 79, 312, 161, 161, 79, 226, 222, 79, 312, 79, 312, 226, 222, 226, 161, 262, 0, 225, 0, 89, 262, 262, 262, 127, 15, 15, 127, 127, 262, 0, 225, 15, 15, 225, 262, 127, 15, 89, 89, 15, 127, 89, 0, 262, 0, 127, 0, 15, 89, 262, 262, 89, 225, 0, 127, 15, 89, 262, 225, 262, 15, 262, 262, 89, 262, 15, 262, 225, 127, 89, 225, 225, 0, 225, 225, 89, 0, 127, 89, 15, 0, 89, 225, 225, 225, 262, 89, 127, 225, 15, 127, 89, 127, 0, 262, 262, 89, 0, 15, 89, 262, 225, 15, 225, 127, 89, 0, 89, 262, 225, 15, 262, 225, 0, 89, 0, 225, 127, 127, 15, 0, 225, 0, 225, 225, 127, 89, 15, 262, 0, 127, 0, 15, 225, 0, 127, 127, 262, 262, 89, 0, 225, 89, 127, 89, 0, 15, 15, 127, 15, 0, 225, 15, 15, 127, 15, 262, 89, 225, 89, 127, 262, 15, 262, 0, 0, 0, 127, 225, 15, 89, 127, 0, 262, 0, 89, 225, 15, 89, 15, 127, 127, 127, 184, 184, 184, 184, 179, 184, 184, 179, 40, 179, 40, 179, 184, 179, 40, 179, 179, 179, 40, 184, 40, 179, 179, 179, 184, 40, 184, 179, 184, 40, 40, 40, 184, 40, 179, 184, 184, 184, 184, 40, 40, 179, 40, 184, 179, 40, 179, 184, 40, 40, 184, 179, 184, 184, 40, 184, 179, 179, 40, 40, 184, 179, 40, 179, 40, 40, 40, 179, 40, 179, 40, 179, 40, 184, 179, 184, 40, 179, 179, 184, 184, 145, 145, 38, 162, 117, 117, 162, 117, 53, 162, 38, 38, 162, 145, 145, 117, 213, 53, 145, 38, 38, 213, 53, 162, 145, 117, 145, 162, 53, 117, 117, 38, 38, 38, 145, 117, 145, 38, 53, 38, 53, 213, 38, 145, 53, 38, 162, 145, 213, 213, 213, 162, 145, 213, 117, 213, 145, 38, 53, 117, 38, 145, 117, 38, 38, 213, 38, 145, 213, 117, 213, 53, 117, 145, 53, 53, 53, 213, 117, 53, 38, 162, 117, 213, 213, 213, 162, 38, 145, 145, 117, 162, 145, 53, 162, 53, 53, 53, 117, 162, 38, 162, 145, 53, 117, 162, 117, 162, 53, 213, 213, 53, 53, 162, 213, 145, 162, 117, 213, 53, 117, 117, 162, 117, 213, 53, 162, 162, 38, 117, 38, 162, 213, 213, 53, 117, 213, 53, 145, 38, 162, 53, 162, 162, 38, 213, 145, 162, 117, 38, 145, 145, 145, 213, 213, 38, 157, 264, 193, 131, 131, 264, 193, 131, 157, 193, 264, 131, 193, 157, 157, 264, 264, 157, 264, 264, 193, 264, 193, 264, 157, 157, 131, 193, 193, 264, 264, 193, 157, 157, 131, 157, 193, 264, 193, 131, 264, 193, 131, 193, 193, 157, 157, 264, 157, 193, 131, 131, 157, 264, 193, 264, 131, 131, 131, 193, 131, 157, 131, 157, 264, 264, 131, 157, 131, 193, 131, 131, 157, 131, 157, 193, 193, 264, 131, 131, 193, 157, 157, 193, 193, 264, 264, 131, 131, 157, 157, 157, 131, 157, 193, 193, 264, 264, 264, 264, 171, 342, 160, 171, 71, 171, 342, 171, 255, 160, 255, 294, 294, 342, 255, 342, 160, 160, 342, 71, 71, 342, 171, 160, 294, 171, 171, 342, 294, 71, 255, 342, 160, 171, 71, 294, 160, 71, 342, 294, 342, 255, 342, 160, 160, 171, 71, 255, 71, 171, 71, 255, 171, 160, 160, 294, 255, 255, 171, 171, 294, 255, 294, 342, 294, 342, 255, 160, 160, 71, 342, 342, 294, 255, 71, 342, 71, 171, 255, 171, 171, 71, 160, 294, 255, 171, 71, 71, 171, 294, 171, 160, 171, 171, 160, 342, 255, 160, 342, 255, 160, 255, 160, 71, 71, 171, 294, 71, 294, 71, 255, 71, 342, 255, 342, 294, 294, 255, 342, 160, 71, 342, 342, 160, 294, 160, 171, 255, 294, 255, 255, 71, 71, 255, 294, 71, 160, 294, 294, 342, 294, 294, 171, 160, 266, 185, 137, 137, 185, 139, 139, 137, 137, 185, 137, 266, 185, 185, 185, 139, 139, 185, 185, 137, 139, 185, 139, 185, 266, 137, 185, 139, 266, 266, 185, 185, 266, 137, 139, 139, 137, 266, 266, 139, 139, 266, 137, 266, 137, 185, 185, 266, 266, 139, 139, 137, 266, 266, 185, 266, 185, 139, 185, 139, 139, 266, 266, 137, 139, 266, 139, 137, 137, 185, 266, 137, 266, 266, 137, 139, 185, 137, 137, 137, 137, 139, 139, 137, 185, 137, 266, 185, 139, 266, 185, 139, 90, 228, 228, 228, 90, 228, 4, 90, 228, 4, 136, 90, 90, 90, 4, 4, 136, 4, 136, 136, 228, 228, 90, 136, 136, 90, 136, 136, 136, 4, 228, 136, 228, 136, 4, 4, 90, 90, 136, 4, 228, 228, 4, 136, 90, 136, 90, 136, 228, 90, 90, 90, 228, 90, 228, 4, 228, 4, 228, 4, 4, 90, 136, 228, 90, 90, 4, 228, 4, 136, 136, 136, 90, 4, 4, 4, 90, 136, 228, 228, 4, 90, 4, 136, 228, 4, 136, 228, 113, 251, 197, 346, 251, 251, 311, 311, 197, 210, 311, 210, 113, 197, 251, 47, 346, 113, 311, 311, 251, 290, 311, 210, 210, 346, 290, 346, 346, 47, 290, 346, 346, 346, 197, 290, 210, 251, 197, 290, 47, 197, 290, 311, 113, 210, 311, 290, 47, 47, 197, 346, 113, 197, 197, 197, 346, 290, 210, 311, 113, 251, 311, 251, 47, 251, 197, 113, 197, 210, 290, 251, 47, 290, 311, 113, 47, 113, 290, 113, 251, 210, 346, 113, 290, 47, 251, 47, 210, 197, 251, 47, 346, 311, 113, 113, 346, 210, 113, 290, 290, 47, 210, 47, 197, 197, 251, 210, 290, 346, 47, 251, 210, 210, 311, 251, 346, 346, 311, 251, 113, 210, 210, 113, 197, 311, 113, 47, 346, 311, 47, 47, 47, 251, 290, 251, 290, 346, 311, 210, 251, 290, 197, 311, 311, 251, 210, 47, 47, 113, 197, 210, 290, 113, 311, 290, 210, 346, 311, 197, 113, 197, 47, 113, 346, 346, 197, 290, 138, 12, 12, 138, 58, 119, 138, 138, 12, 119, 119, 58, 58, 12, 12, 58, 119, 12, 58, 138, 119, 12, 138, 12, 58, 12, 138, 58, 119, 58, 138, 119, 12, 119, 119, 138, 138, 119, 58, 58, 119, 119, 119, 12, 12, 12, 58, 138, 138, 58, 12, 138, 138, 119, 58, 58, 12, 119, 138, 119, 58, 138, 58, 58, 12, 58, 58, 12, 12, 138, 119, 119, 12, 138, 58, 138, 119, 138, 12, 119, 345, 270, 196, 338, 338, 270, 345, 283, 270, 283, 283, 338, 338, 324, 338, 338, 345, 324, 196, 345, 324, 196, 338, 196, 324, 283, 324, 196, 263, 270, 263, 263, 324, 345, 283, 263, 263, 324, 270, 338, 324, 345, 263, 263, 270, 338, 263, 196, 270, 338, 345, 263, 270, 196, 283, 270, 283, 338, 263, 196, 283, 270, 283, 324, 338, 196, 196, 324, 338, 263, 270, 263, 283, 338, 283, 345, 345, 270, 338, 196, 196, 345, 196, 324, 324, 263, 196, 345, 283, 270, 270, 345, 283, 324, 345, 196, 345, 338, 283, 270, 345, 324, 270, 338, 283, 270, 345, 270, 270, 263, 324, 324, 324, 283, 345, 196, 196, 263, 283, 345, 338, 263, 263, 324, 324, 283, 263, 196, 283, 263, 345, 196, 338, 208, 318, 191, 191, 208, 318, 85, 318, 150, 191, 191, 208, 85, 150, 85, 150, 278, 85, 191, 150, 208, 208, 85, 150, 150, 150, 208, 318, 191, 278, 150, 318, 85, 191, 208, 85, 208, 150, 85, 150, 278, 85, 191, 85, 208, 208, 208, 318, 208, 278, 191, 318, 318, 278, 85, 318, 318, 318, 191, 150, 278, 278, 318, 278, 85, 318, 318, 150, 278, 85, 208, 278, 318, 278, 278, 278, 150, 318, 318, 278, 85, 85, 85, 150, 191, 208, 278, 150, 191, 191, 191, 85, 318, 278, 150, 278, 191, 208, 191, 191, 191, 208, 278, 150, 208, 150, 85, 208, 187, 153, 276, 97, 245, 314, 153, 153, 112, 9, 9, 190, 246, 97, 153, 314, 97, 246, 276, 153, 108, 276, 276, 187, 153, 9, 314, 190, 245, 9, 108, 112, 108, 97, 112, 108, 314, 112, 245, 108, 276, 108, 187, 112, 108, 276, 187, 153, 97, 314, 112, 187, 97, 108, 245, 153, 276, 112, 245, 112, 9, 9, 314, 112, 190, 190, 9, 245, 190, 276, 153, 246, 97, 246, 314, 190, 97, 245, 112, 9, 108, 108, 108, 112, 97, 112, 97, 245, 245, 9, 314, 9, 97, 108, 314, 314, 246, 314, 246, 246, 246, 187, 245, 245, 276, 97, 276, 97, 187, 246, 112, 190, 9, 190, 246, 108, 187, 187, 276, 153, 108, 314, 190, 9, 112, 108, 112, 187, 190, 153, 246, 153, 9, 314, 153, 97, 276, 190, 314, 9, 245, 187, 153, 276, 97, 187, 245, 314, 153, 276, 246, 187, 187, 97, 190, 245, 246, 276, 190, 97, 190, 190, 246, 187, 190, 9, 245, 187, 314, 276, 187, 9, 245, 108, 246, 190, 153, 153, 246, 112, 276, 112, 9, 108, 245, 246, 314, 287, 238, 126, 265, 238, 158, 158, 344, 238, 287, 126, 238, 287, 158, 287, 287, 158, 265, 158, 344, 126, 344, 344, 344, 126, 126, 126, 158, 344, 126, 287, 344, 265, 126, 287, 265, 158, 344, 265, 287, 126, 238, 287, 287, 126, 158, 265, 287, 265, 265, 344, 126, 344, 344, 238, 344, 158, 158, 158, 238, 344, 265, 238, 126, 287, 287, 265, 126, 238, 238, 238, 344, 158, 238, 238, 344, 126, 158, 238, 238, 265, 287, 238, 265, 265, 287, 126, 344, 265, 265, 158, 265, 126, 158, 158, 287, 337, 297, 303, 334, 200, 334, 217, 303, 303, 217, 217, 337, 334, 327, 334, 334, 334, 217, 297, 303, 217, 297, 217, 327, 337, 334, 327, 297, 297, 297, 334, 327, 303, 200, 217, 327, 337, 334, 337, 200, 244, 297, 327, 200, 200, 217, 297, 217, 327, 200, 200, 200, 303, 200, 244, 297, 244, 334, 244, 244, 244, 334, 200, 303, 244, 244, 303, 337, 303, 244, 244, 217, 200, 337, 327, 337, 200, 303, 297, 217, 303, 337, 297, 244, 327, 303, 303, 303, 244, 200, 327, 327, 334, 217, 337, 200, 327, 337, 337, 337, 334, 327, 297, 217, 244, 327, 327, 217, 244, 297, 217, 334, 297, 337, 200, 297, 303, 244, 334, 337, 50, 172, 172, 50, 35, 50, 172, 24, 35, 56, 330, 148, 281, 281, 73, 50, 333, 286, 281, 177, 73, 25, 25, 333, 186, 50, 281, 281, 330, 24, 172, 296, 24, 56, 177, 56, 56, 50, 148, 73, 51, 333, 333, 24, 73, 330, 172, 50, 330, 177, 286, 296, 25, 25, 286, 321, 333, 56, 177, 24, 51, 286, 330, 281, 35, 281, 186, 24, 51, 73, 286, 35, 343, 296, 25, 172, 177, 2, 35, 172, 186, 330, 56, 51, 35, 2, 330, 2, 51, 333, 296, 333, 2, 321, 35, 330, 50, 2, 24, 296, 177, 177, 296, 25, 186, 186, 50, 51, 321, 51, 343, 24, 333, 296, 51, 186, 281, 35, 186, 330, 343, 172, 186, 321, 286, 2, 172, 177, 148, 286, 56, 343, 24, 2, 343, 148, 56, 148, 148, 73, 296, 296, 286, 281, 177, 321, 24, 25, 343, 296, 148, 321, 51, 172, 296, 73, 296, 177, 35, 333, 186, 330, 321, 286, 343, 177, 148, 56, 25, 343, 25, 186, 73, 35, 73, 50, 186, 172, 148, 2, 281, 24, 35, 281, 186, 51, 343, 281, 172, 343, 286, 73, 177, 24, 321, 321, 148, 24, 286, 321, 35, 50, 56, 35, 286, 148, 321, 25, 51, 56, 333, 73, 333, 2, 56, 50, 2, 186, 330, 2, 2, 24, 2, 343, 321, 73, 73, 330, 148, 35, 51, 25, 286, 330, 25, 343, 333, 296, 186, 281, 56, 321, 51, 50, 148, 333, 343, 51, 330, 281, 25, 50, 177, 172, 296, 25, 321, 172, 148, 56, 286, 177, 333, 2, 73, 343, 60, 240, 60, 80, 240, 205, 146, 80, 298, 60, 60, 75, 146, 205, 267, 205, 75, 146, 308, 240, 146, 267, 240, 298, 60, 267, 205, 146, 298, 298, 146, 205, 267, 146, 205, 75, 267, 80, 240, 308, 240, 75, 205, 308, 80, 308, 240, 146, 80, 267, 308, 75, 80, 267, 298, 267, 60, 80, 240, 146, 60, 240, 146, 308, 80, 75, 240, 80, 298, 60, 80, 298, 60, 240, 298, 308, 75, 205, 75, 298, 298, 205, 308, 240, 267, 267, 308, 308, 60, 308, 75, 205, 75, 298, 75, 240, 75, 267, 298, 205, 60, 298, 60, 146, 75, 205, 267, 308, 267, 308, 80, 80, 60, 205, 146, 80, 146, 326, 234, 291, 169, 234, 291, 135, 65, 135, 3, 3, 3, 81, 326, 65, 3, 169, 301, 301, 234, 81, 326, 234, 81, 81, 313, 313, 234, 313, 326, 169, 65, 259, 3, 81, 3, 3, 81, 301, 135, 135, 135, 65, 259, 169, 81, 291, 301, 301, 169, 259, 169, 135, 291, 259, 234, 234, 135, 326, 301, 234, 135, 65, 291, 169, 326, 291, 291, 3, 313, 313, 259, 234, 259, 301, 3, 65, 291, 65, 65, 81, 65, 135, 259, 135, 313, 65, 301, 259, 259, 313, 81, 301, 169, 234, 234, 259, 234, 65, 313, 326, 169, 3, 3, 169, 169, 291, 291, 326, 135, 326, 81, 3, 326, 81, 259, 291, 313, 326, 313, 259, 313, 326, 313, 301, 291, 169, 301, 81, 65, 135, 301, 134, 216, 99, 7, 214, 216, 189, 214, 7, 34, 284, 134, 100, 216, 29, 335, 77, 26, 216, 247, 247, 7, 247, 34, 174, 335, 26, 77, 189, 174, 100, 174, 77, 284, 247, 77, 335, 284, 175, 34, 214, 174, 34, 100, 216, 134, 189, 7, 34, 247, 284, 174, 335, 174, 29, 214, 247, 214, 189, 100, 174, 216, 335, 34, 134, 247, 34, 214, 99, 29, 174, 99, 174, 284, 26, 189, 100, 335, 216, 134, 7, 100, 174, 216, 100, 284, 214, 175, 214, 29, 29, 189, 7, 175, 175, 175, 216, 100, 189, 7, 99, 26, 247, 77, 26, 26, 284, 34, 29, 335, 175, 77, 284, 134, 175, 99, 77, 29, 216, 100, 335, 26, 189, 26, 29, 7, 284, 134, 174, 29, 99, 34, 77, 189, 214, 335, 26, 99, 34, 189, 214, 335, 216, 29, 134, 284, 247, 77, 77, 77, 99, 284, 175, 26, 99, 335, 7, 99, 7, 34, 99, 175, 175, 175, 247, 29, 214, 100, 247, 100, 134, 134, 189, 26, 7, 134, 302, 339, 43, 128, 128, 128, 57, 16, 221, 221, 302, 253, 43, 1, 221, 43, 27, 253, 295, 43, 339, 212, 295, 16, 295, 43, 195, 339, 43, 341, 295, 282, 295, 27, 253, 253, 1, 195, 1, 212, 253, 221, 282, 295, 339, 27, 339, 282, 339, 16, 57, 295, 57, 43, 282, 339, 253, 212, 221, 339, 253, 57, 43, 212, 282, 128, 1, 302, 212, 128, 1, 57, 282, 195, 282, 221, 195, 27, 212, 212, 295, 27, 43, 195, 195, 302, 302, 16, 128, 253, 341, 295, 57, 302, 195, 57, 195, 57, 1, 27, 295, 212, 128, 128, 341, 212, 43, 302, 341, 221, 221, 339, 16, 1, 341, 302, 16, 128, 282, 253, 341, 1, 27, 1, 195, 282, 27, 27, 195, 341, 27, 341, 16, 57, 341, 212, 302, 221, 128, 253, 341, 302, 1, 16, 221, 282, 57, 16, 339, 16, 315, 116, 257, 273, 82, 82, 183, 82, 116, 42, 116, 274, 183, 274, 336, 307, 149, 83, 242, 82, 19, 78, 82, 256, 256, 88, 273, 257, 306, 149, 183, 274, 256, 109, 83, 194, 42, 109, 19, 39, 19, 82, 194, 109, 306, 83, 42, 273, 336, 39, 109, 183, 109, 307, 82, 19, 78, 83, 306, 19, 257, 307, 307, 306, 274, 315, 273, 109, 19, 194, 88, 306, 39, 109, 242, 306, 307, 274, 149, 257, 242, 88, 194, 42, 88, 39, 83, 149, 83, 242, 307, 256, 88, 336, 242, 315, 116, 306, 78, 149, 256, 83, 82, 315, 257, 242, 42, 336, 315, 83, 256, 307, 19, 336, 306, 307, 39, 42, 257, 39, 273, 116, 149, 242, 274, 274, 256, 116, 257, 88, 306, 273, 242, 39, 315, 116, 149, 336, 336, 194, 274, 109, 256, 336, 78, 315, 88, 88, 19, 78, 273, 109, 78, 88, 307, 83, 39, 315, 183, 194, 194, 273, 19, 183, 315, 39, 116, 256, 194, 116, 78, 78, 257, 194, 42, 183, 183, 149, 257, 78, 183, 42, 242, 82, 42, 274, 336, 149, 273, 118, 49, 87, 165, 249, 87, 215, 167, 87, 258, 202, 164, 32, 258, 220, 249, 118, 220, 258, 332, 249, 164, 258, 304, 224, 248, 249, 215, 224, 49, 37, 14, 254, 258, 164, 118, 249, 14, 332, 305, 220, 202, 165, 254, 305, 14, 49, 14, 49, 167, 32, 332, 167, 202, 14, 243, 254, 167, 87, 118, 304, 167, 249, 215, 224, 332, 167, 248, 37, 332, 236, 305, 202, 236, 249, 243, 236, 236, 32, 227, 236, 215, 167, 32, 236, 87, 32, 254, 164, 243, 87, 254, 258, 49, 165, 37, 332, 32, 14, 164, 304, 224, 248, 61, 165, 164, 96, 332, 305, 304, 236, 304, 254, 227, 220, 254, 220, 87, 165, 32, 215, 61, 96, 49, 227, 32, 304, 165, 304, 248, 215, 243, 14, 37, 37, 227, 202, 305, 215, 87, 248, 96, 37, 37, 61, 305, 227, 96, 243, 215, 220, 202, 248, 220, 224, 167, 118, 305, 164, 96, 243, 202, 61, 118, 61, 305, 224, 165, 118, 227, 164, 37, 248, 220, 332, 96, 61, 96, 248, 49, 61, 258, 14, 224, 118, 258, 61, 236, 227, 304, 165, 249, 243, 254, 49, 224, 96, 243, 227, 202, 54, 11, 11, 20, 288, 292, 11, 41, 261, 6, 41, 6, 17, 64, 17, 54, 288, 54, 17, 156, 17, 241, 20, 20, 230, 20, 292, 54, 241, 288, 261, 41, 11, 261, 292, 6, 31, 31, 17, 155, 155, 241, 230, 261, 156, 155, 241, 155, 155, 241, 292, 31, 41, 17, 6, 31, 54, 230, 241, 156, 230, 288, 292, 155, 20, 64, 230, 261, 241, 288, 156, 64, 155, 11, 17, 156, 20, 6, 11, 54, 6, 156, 230, 41, 261, 288, 64, 54, 31, 31, 230, 41, 64, 6, 288, 64, 31, 20, 41, 292, 292, 156, 11, 261, 64, 269, 141, 348, 260, 268, 285, 348, 132, 152, 152, 45, 211, 168, 252, 235, 36, 147, 151, 21, 250, 62, 13, 348, 180, 235, 93, 62, 201, 59, 159, 132, 349, 180, 151, 309, 323, 168, 309, 62, 201, 45, 132, 168, 69, 21, 180, 69, 260, 21, 349, 349, 59, 45, 163, 62, 141, 48, 309, 323, 147, 48, 268, 45, 74, 159, 52, 59, 36, 268, 152, 159, 93, 141, 141, 268, 219, 141, 348, 62, 250, 121, 74, 285, 180, 74, 219, 74, 166, 299, 299, 147, 163, 349, 328, 285, 152, 260, 201, 323, 69, 285, 252, 163, 269, 48, 235, 252, 268, 159, 201, 309, 159, 93, 211, 48, 74, 349, 59, 235, 299, 252, 268, 52, 285, 166, 323, 62, 151, 250, 328, 36, 328, 309, 211, 168, 328, 48, 269, 201, 211, 219, 93, 13, 159, 52, 45, 250, 147, 69, 299, 260, 59, 328, 147, 168, 36, 13, 36, 349, 132, 328, 152, 151, 250, 151, 269, 348, 166, 141, 121, 52, 219, 36, 74, 323, 52, 180, 211, 21, 152, 269, 147, 348, 201, 219, 299, 69, 21, 269, 93, 48, 163, 59, 260, 250, 252, 121, 168, 163, 323, 13, 211, 132, 180, 285, 163, 93, 166, 235, 13, 69, 121, 45, 260, 252, 21, 235, 166, 166, 13, 121, 52, 121, 219, 151, 299, 309, 132]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load phoBERT tokenizer"
      ],
      "metadata": {
        "id": "_R14rC6nZDVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)"
      ],
      "metadata": {
        "id": "7B_rRMMoZGUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d7be24-8e3c-47cb-f3e5-d30166ef5968"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"công tyNếu tính GJK\"\n",
        "print(tokenizer.encode(text))\n",
        "text = \"công ty Nếu tính gjk\"\n",
        "print(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_goEc8618VXw",
        "outputId": "9937b07c-9b8c-4ec2-8513-457c6684faef"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 675, 6745, 313, 294, 1276, 2136, 2260, 2]\n",
            "[0, 675, 6892, 313, 294, 1529, 57202, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters\n"
      ],
      "metadata": {
        "id": "dtdcZMIXyWP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 512  # Adjust as needed\n",
        "BATCH_SIZE = 32\n",
        "N_CLASSES = number_of_classes  # Replace with your actual number of classes\n",
        "EPOCHS = 30"
      ],
      "metadata": {
        "id": "ylRDFeY_ZB3G"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Lightning DataModule"
      ],
      "metadata": {
        "id": "r4dNQIiL6XaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Data_Module(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(self, trainset, valset, labels, batch_size: int = 32, max_token_length: int = 512, tokenizer=None):\n",
        "    super().__init__()\n",
        "    self.trainset = trainset\n",
        "    self.val_path = valset\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    self.max_token_length = max_token_length\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def setup(self, stage = None):\n",
        "    if stage in (None, \"fit\"):\n",
        "      self.train_dataset = ArticleDataset(self.trainset, self.labels, self.tokenizer, self.max_token_length)\n",
        "      self.val_dataset = ArticleDataset(self.val_path, self.labels, self.tokenizer, self.max_token_length)\n",
        "    if stage == 'predict':\n",
        "      self.val_dataset = ArticleDataset(self.val_path, self.labels, self.tokenizer, self.max_token_length)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset, batch_size = self.batch_size, num_workers=2, shuffle=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.val_dataset, batch_size = self.batch_size, num_workers=2, shuffle=False)\n",
        "\n",
        "  def predict_dataloader(self):\n",
        "    return DataLoader(self.val_dataset, batch_size = self.batch_size, num_workers=2, shuffle=False)"
      ],
      "metadata": {
        "id": "t_S6YmZv6dBJ"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create PyTorch lightning DataLoader"
      ],
      "metadata": {
        "id": "8_GghUzA9dYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create PyTorch lightning DataLoader\n",
        "data_loader = Data_Module(trainset, valset, labels, BATCH_SIZE, MAX_LENGTH, tokenizer)\n",
        "data_loader.setup()"
      ],
      "metadata": {
        "id": "9EQkuLqcZR5q"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model architecture"
      ],
      "metadata": {
        "id": "MXBH2wQtyZqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wLuZ3CjDfn58",
        "outputId": "a459683f-4e31-4030-8f61-dbd0259e5ce5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ArticleClassifier(pl.LightningModule):\n",
        "    def __init__(self, config: dict):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.bert = AutoModel.from_pretrained(config['model_name'], return_dict = True)\n",
        "        self.batch_norm = nn.BatchNorm1d(self.bert.config.hidden_size)\n",
        "        self.fc1 = nn.Linear(self.bert.config.hidden_size, 128)  # Adjusted the input size to match the bert's hidden size\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "        self.dropout2 = nn.Dropout(0.4)\n",
        "        self.layer_norm = LayerNorm(256)\n",
        "        self.output = nn.Linear(256, self.config['n_labels'])\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        x = self.bert(input_ids, attention_mask=attention_mask)[0]\n",
        "        x = torch.mean(x, 1)\n",
        "        x = self.batch_norm(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.layer_norm(x)\n",
        "        x = self.output(x)  # Remove softmax activation here\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "        outputs = self(input_ids, attention_mask)\n",
        "        loss = self.loss(outputs, labels)\n",
        "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
        "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "        outputs = self(input_ids, attention_mask)\n",
        "        loss = self.loss(outputs, labels)\n",
        "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
        "        return {\"val_loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        outputs = self(input_ids, attention_mask)\n",
        "        return outputs\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
        "        total_steps = self.config['train_size']/self.config['batch_size']\n",
        "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "        return [optimizer],[scheduler]"
      ],
      "metadata": {
        "id": "WXpnzKDQY2Vp"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Model"
      ],
      "metadata": {
        "id": "17n-Sl-wZYG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model configuration"
      ],
      "metadata": {
        "id": "MnnxrRBj2tnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'model_name': 'vinai/phobert-base',\n",
        "    'n_labels': number_of_classes,\n",
        "    'batch_size': 128,\n",
        "    'lr': 1.5e-6,\n",
        "    'warmup': 0.2,\n",
        "    'train_size': len(data_loader.train_dataloader()),\n",
        "    'weight_decay': 0.001,\n",
        "    'n_epochs': 100\n",
        "}"
      ],
      "metadata": {
        "id": "8rhH-JU02wrV"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "2Q3dmcBV2zw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize our classifier\n",
        "model = ArticleClassifier(config)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "J2d9tBNoZdVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7162a62-59d6-42e5-a7f7-879018d34659"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Train Model"
      ],
      "metadata": {
        "id": "43JH6zpgZlsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(max_epochs=config['n_epochs'], num_sanity_val_steps=50)\n",
        "trainer.fit(model, data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867,
          "referenced_widgets": [
            "ca897cb5bc5c48a5b07aef004b48e6c9",
            "b6f2aa1bb3e5475788d4beacb53a84c2",
            "1ce085b4f6824c7e9545b2149c55881e",
            "3cda02b123824f2b96410a4ddf4383c4",
            "e4c6430487224597b1d8691d425058e2",
            "f3b6a72d7d834285943a0f7d44e7edf5",
            "7f35cd7eefb945868c066cc78dfdf570",
            "27a2d4ecc75c42ada6b24a11d8f6eb5d",
            "562a5eddbc904ebbaeaf1081a0cdc38a",
            "b6f19edfe0084276b1cfc519a1f55e14",
            "7780d5ed290e45d19d783cc392cd6b79"
          ]
        },
        "id": "HFHQxP6T5B8T",
        "outputId": "be213694-ab71-45c3-e206-ade12beaf1d5"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name       | Type             | Params\n",
            "------------------------------------------------\n",
            "0 | bert       | RobertaModel     | 134 M \n",
            "1 | batch_norm | BatchNorm1d      | 1.5 K \n",
            "2 | fc1        | Linear           | 98.4 K\n",
            "3 | dropout1   | Dropout          | 0     \n",
            "4 | fc2        | Linear           | 33.0 K\n",
            "5 | dropout2   | Dropout          | 0     \n",
            "6 | layer_norm | LayerNorm        | 512   \n",
            "7 | output     | Linear           | 90.0 K\n",
            "8 | loss       | CrossEntropyLoss | 0     \n",
            "------------------------------------------------\n",
            "135 M     Trainable params\n",
            "0         Non-trainable params\n",
            "135 M     Total params\n",
            "540.887   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca897cb5bc5c48a5b07aef004b48e6c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-270e0e2b4a27>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sanity_val_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_unwrap_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         )\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mprevious_dataloader_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;31m# run step hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_step\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidationStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-124-fac51feb58e1>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-124-fac51feb58e1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (512) must match the existing size (258) at non-singleton dimension 1.  Target sizes: [32, 512].  Tensor sizes: [1, 258]"
          ]
        }
      ]
    }
  ]
}